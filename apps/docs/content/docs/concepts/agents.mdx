---
title: Agents
---

Agents are **Large Language Models (LLMs)** that use **tools** in a **loop** to accomplish complex tasks. Unlike standard generation, an agent can observe the results of its actions and decide on the next step autonomously.

In AISDK, these components work together:
- **LLMs**: Act as the "brain," processing input and deciding which actions to take.
- **Tools**: Extend the model's capabilities (e.g., searching the web, querying a database).
- **Loop**: orchestrates execution through:
	- **Context management** - Maintaining conversation history and deciding what the model sees at each step
	- **Stopping conditions** - Determining when the loop (task) is complete

## The Agentic Loop

When you provide tools to a [LanguageModelRequest](/docs/concepts/language-model-request), AISDK automatically manages the agentic loop. 

1. **Reasoning**: The model decides to call one or more tools.
2. **Action**: AISDK executes the tools and captures their results.
3. **Observation**: The results are fed back into the conversation history.
4. **Re-evaluation**: The model decides the next step based on the new context.

### Loop Control (`stop_when`)

Because agents operate in a loop, it is critical to prevent infinite execution or excessive token usage. AISDK provides the `.stop_when()` method to define explicit exit conditions.

The `stop_when` method accepts a closure with the following signature:
`Fn(&LanguageModelOptions) -> bool`

This closure receives the current state of the request (including all interaction history and options) and returns `true` if the loop should terminate.

#### Using `step_count_is`

The most common way to control an agent loop is by limiting the number of turns. AISDK provides a `step_count_is(n)` utility for this purpose.

```rust
use aisdk::core::utils::step_count_is;

let request = LanguageModelRequest::builder()
    .model(OpenAI::gpt_5())
    .prompt("Research the history of Rust and summarize it.")
    .with_tool(search_web())
    .stop_when(step_count_is(5)) // Exit after 5 turns
    .build();
```

## Core Example: The Weather Agent

Here is a complete agent that uses multiple tools in a loop to answer complex queries.

```rust
use aisdk::core::{LanguageModelRequest, Tool, utils::step_count_is};
use aisdk::providers::openai::OpenAI;
use aisdk::macros::tool;

#[tool]
/// Get the current weather in a specific location
fn get_weather(location: String) -> Tool {
    // In a real app, this would call a weather API
    Ok(format!("The weather in {} is 72°F and sunny.", location))
}

#[tool]
/// Convert Fahrenheit to Celsius
fn fahrenheit_to_celsius(f: f32) -> Tool {
    let c = (f - 32.0) * 5.0 / 9.0;
    Ok(format!("{:.1}°C", c))
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let openai = OpenAI::gpt_5();

    let mut response = LanguageModelRequest::builder()
        .model(openai)
        .system("You are a helpful weather assistant.")
        .prompt("What is the weather in San Francisco in Celsius?")
        .with_tool(get_weather())
        .with_tool(fahrenheit_to_celsius())
        .stop_when(step_count_is(10))
        .build()
        .generate_text()
        .await?;

    println!("Final Answer: {:?}", response.text());
    
    // Inspect the steps taken
    for step in response.steps() {
        println!("Turn {}: Usage: {:?}", step.step_id, step.usage());
    }

    Ok(())
}
```

## Lifecycle Hooks

Hooks allow you to intercept the agent at different stages of its thinking process. This is powerful for logging, custom moderation, or dynamically adjusting the agent's context.

### `on_step_start`
Runs before the model generates a response for a specific step.
- **Use case**: Log the exact context being sent to the model for debugging.

### `on_step_finish`
Runs after a model response is received but before tools are executed (or after the final response).
- **Use case**: Intercept a model's request to call a "dangerous" tool and ask for user permission.

```rust
.on_step_finish(|opts| {
    if let Some(tool_calls) = opts.last_step().tool_calls() {
        println!("The agent wants to call {} tools.", tool_calls.len());
    }
})
```

## Workflow Patterns

While the automatic loop is powerful, many production systems require more structure. You can combine core AISDK primitives to implement advanced orchestration patterns.

### Routing
Use a fast/cheap model to classify a query, then route it to a specialized agent or workflow.

```rust
use schemars::JsonSchema;
use serde::Deserialize;

#[derive(JsonSchema, Deserialize, Debug)]
enum QueryType {
    Technical,
    Billing,
    General,
}

// 1. Classify the query using Structured Output
let mut response = LanguageModelRequest::builder()
    .model(OpenAI::gpt_4o_mini())
    .prompt(user_query)
    .schema::<QueryType>()
    .build()
    .generate_text()
    .await?;

let query_type: QueryType = response.into_schema().unwrap();

// 2. Route to specialized logic
match query_type {
    QueryType::Technical => handle_technical(user_query).await?,
    QueryType::Billing => handle_billing(user_query).await?,
    QueryType::General => handle_general(user_query).await?,
};
```

### Sequential Chains
Chains execute steps in a predefined order where the output of one request becomes the input for the next.

```rust
// Step 1: Generate summary
let summary = LanguageModelRequest::builder()
    .model(OpenAI::gpt_5())
    .prompt(format!("Summarize this article: {}", article))
    .build()
    .generate_text()
    .await?;

// Step 2: Translate the summary
let translation = LanguageModelRequest::builder()
    .model(OpenAI::gpt_5())
    .prompt(format!("Translate this to French: {:?}", summary.text()))
    .build()
    .generate_text()
    .await?;
```

### Parallel Processing
Execute independent tasks concurrently using `tokio::try_join!` to reduce total latency.

```rust
let (security, performance) = tokio::try_join!(
    run_security_audit(code), // Internal functions returning Results
    run_performance_benchmark(code)
)?;
```

### Evaluator-Optimizer
One request generates a solution, while a second critques and improves it.

```rust
// 1. Initial Draft
let draft = LanguageModelRequest::builder()
    .model(OpenAI::gpt_5())
    .prompt("Write a startup pitch for a solar-powered toaster.")
    .build()
    .generate_text()
    .await?;

// 2. Refined Draft with Critique
let refined = LanguageModelRequest::builder()
    .model(OpenAI::gpt_5())
    .system("You are a picky investor.")
    .prompt(format!("Critique and improve this pitch: {:?}", draft.text()))
    .build()
    .generate_text()
    .await?;
```

## Next Steps
- Learn how to create [Custom Tools](/docs/concepts/tools).
- Explore [Structured Output](/docs/concepts/structuredoutput) for reliable agent data.
- See how [Capabilities](/docs/concepts/language-model-request#capability-system) protect your agent logic.
